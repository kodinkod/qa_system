{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры использования API OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt-3.5-turbo - gpt-3.5-turbo-0301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_chat(data):\n",
    "    \"\"\"Получение отета от gpt_3.5\n",
    "\n",
    "    Args:\n",
    "        data: данные с api gpt_3.5\n",
    "\n",
    "    Returns:\n",
    "        str:  строка вида роль: ответ\n",
    "    \"\"\"\n",
    "    text = data['choices'][0]['message']['content']\n",
    "    role = data['choices'][0]['message']['role']\n",
    "    total_tokens = data[\"usage\"]['total_tokens']\n",
    "\n",
    "    return role + ': ' + text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_completion(data):\n",
    "    return data['choices'][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "Prompt engineering - это методология разработки программного обеспечения, которая основывается на использовании промптов (подсказок) для управления процессом разработки. Она предполагает, что разработчик должен получать подсказки на каждом этапе разработки, чтобы убедиться, что он выполняет задачи правильно и в соответствии с требованиями заказчика. Это позволяет ускорить процесс разработки, уменьшить количество ошибок и повысить качество конечного продукта.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Концепция Prompt engineering это\n",
    "\"\"\"  \n",
    "\n",
    "mes = [\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    " ]\n",
    "response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages= mes,\n",
    "        temperature = 0\n",
    "    )\n",
    "text = response['choices'][0]['message']['content']\n",
    "role = response['choices'][0]['message']['role']\n",
    "\n",
    "print(role)\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Дозор - это программное обеспечение для доставки еды. Он позволяет пользователям заказывать еду из местных ресторанов и получать ее в удобное для них время. Программа предоставляет пользователям простой и удобный интерфейс для поиска и заказа еды.\n"
     ]
    }
   ],
   "source": [
    "info = \"Дозор это прогрмма по доставке еды\"\n",
    "question = \"Что такое дозор?\"\n",
    "\n",
    "prompt = \"Привет! Ты ассистент помошник по использованию програмного продукта 'Дозор' \\\n",
    "            'Дозор'. Будь вежлив и краток. Здоровайся с каждым пользователем! Используй эту информайию:\" + info +\\\n",
    "            \"чтобы отвветить на мой вопрос: \" + question\n",
    "\n",
    "text = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt= prompt,\n",
    "  max_tokens=505,\n",
    "  temperature=0\n",
    ")\n",
    "\n",
    "print(text['choices'][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "В Ростове на Дону в данный момент преимущественно солнечно, температура воздуха около +20 градусов. Ветер слабый.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Привет! Какая погода в Ростове на Дону?\"\n",
    "\n",
    "text = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt= prompt,\n",
    "  max_tokens=505,\n",
    "  temperature=0\n",
    ")\n",
    "\n",
    "print(text['choices'][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "На Дону тонкая, слабая и вероятно небольшая погода.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Привет! Какая погода в Ростове на Дону?\"\n",
    "\n",
    "text = openai.Completion.create(\n",
    "  model=\"text-babbage-001\",\n",
    "  prompt= prompt,\n",
    "  max_tokens=505,\n",
    "  temperature=0\n",
    ")\n",
    "\n",
    "print(text['choices'][0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
